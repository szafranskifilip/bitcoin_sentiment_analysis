{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Determination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import datetime\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import key and tokens from config.py\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload pre-trained model\n",
    "model = load_model('rnn_best_models/best_model_gru.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_tweets(query=\"(#btc OR #bitcoin OR bitcoin) is:verified -has:media -is:retweet lang:en\"):\n",
    "    \n",
    "    \"\"\" \n",
    "    Function imports recent tweets from last 7 days. \n",
    "    Default query is: \"(#btc OR #bitcoin OR bitcoin) is:verified -has:media -is:retweet lang:en\" \n",
    "    Returns file path of csv file with tweets' data.\n",
    "    File name indicates start and end dates, i.e 2022-03-05T22:45:00Z_2022-02-27T00:45:00Z.csv.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Provide access tokens\n",
    "    client = tweepy.Client(bearer_token=bearer_token, \n",
    "                       consumer_key=consumer_key, \n",
    "                       consumer_secret=consumer_secret, \n",
    "                       access_token=acces_token, \n",
    "                       access_token_secret=token_secret,\n",
    "                       wait_on_rate_limit=True)\n",
    "    \n",
    "    #Get dates in ISO format YYYY-MM-DDTHH:mm:ssZ (ISO 8601/RFC 3339).\n",
    "    #today('end_time') must be a minimum of 10 seconds prior to the request time. \n",
    "    #We add an hour to avoid the newest tweets without comlete public metrics data \n",
    "    today = datetime.now() - timedelta(hours=1) + timedelta(hours=5)\n",
    "    seven_days_back = today - timedelta(days=6, hours=22)\n",
    "\n",
    "    today = today.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    seven_days_back = seven_days_back.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    \n",
    "    #Open/create a file to append data to\n",
    "    csvFile = open('api_csv/' + today + '_' + seven_days_back + '.csv', 'a')\n",
    "\n",
    "    # # Use csv writer\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "\n",
    "    csvWriter.writerow(['item.id',\n",
    "                        'item.author_id',\n",
    "                        'item.created_at',\n",
    "                        'item.source', \n",
    "                        'item.public_metrics[\"retweet_count\"]',\n",
    "                        'item.public_metrics[\"reply_count\"]',\n",
    "                        'item.public_metrics[\"like_count\"]',\n",
    "                        'item.public_metrics[\"like_count\"]',\n",
    "                        'item.text'])\n",
    "\n",
    "    for response in tweepy.Paginator(client.search_recent_tweets, query=query, \n",
    "                                  start_time=str(seven_days_back),\n",
    "                                  end_time=str(today),\n",
    "                                  tweet_fields='id,author_id,created_at,geo,public_metrics,source,text',\n",
    "                                  user_fields='id,name,username,public_metrics',\n",
    "                                  place_fields='full_name,country,country_code,geo',\n",
    "                                  expansions='author_id,geo.place_id',\n",
    "                                  max_results=100, limit=1200):\n",
    "\n",
    "        # Write a row to the CSV file. I use encode UTF-8\n",
    "        for item in response.data:\n",
    "            # Write a row to the CSV file. I use encode UTF-8\n",
    "            csvWriter.writerow([item.id,\n",
    "                                item.author_id,\n",
    "                                item.created_at,\n",
    "                                item.source, \n",
    "                                item.public_metrics[\"retweet_count\"],\n",
    "                                item.public_metrics[\"reply_count\"],\n",
    "                                item.public_metrics[\"like_count\"],\n",
    "                                item.public_metrics[\"like_count\"],\n",
    "                                item.text])\n",
    "\n",
    "    csvFile.close()\n",
    "    \n",
    "    file_path = 'api_csv/' + today + '_' + seven_days_back + '.csv'\n",
    "    \n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweets(file_path):\n",
    "    \"\"\" \n",
    "    Function processes and cleans up csv file.  \n",
    "    Returns file path of csv file with tweets' data.\n",
    "    \"\"\"\n",
    "    df_tweets = pd.read_csv(file_path)\n",
    "    df_text = df_tweets[['item.created_at', 'item.text']]\n",
    "    df_text.columns = ['created_at', 'text']\n",
    "    \n",
    "    return df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text, \n",
    "                 max_tweet_len=45,\n",
    "                 model = model):\n",
    "    \"\"\" \n",
    "    Function processes tweet text content and create additional column with snetiment result.  \n",
    "    Predictions are made with pre-trained RNN model.\n",
    "    \"\"\"\n",
    "    \n",
    "    label_names = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "    \n",
    "    text = [text]\n",
    "    \n",
    "    # Convert training data into tensors to feed into neural net\n",
    "    t = Tokenizer()\n",
    "    # Create tokenizer\n",
    "    t.fit_on_texts(text)\n",
    "    \n",
    "    # This class allows to vectorize a text corpus, by turning each text into either a sequence of integers\n",
    "    sequences = t.texts_to_sequences(text)\n",
    "    \n",
    "    #Truncate and pad input sequences to be all the same lenght vectors\n",
    "    padded_data = pad_sequences(sequences, maxlen=max_tweet_len)\n",
    "\n",
    "    pred = model.predict(padded_data)\n",
    "    \n",
    "    return label_names[np.argmax(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new csv file with tweets' data\n",
    "file_path = import_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process the csv file - create a dataframe with the \n",
    "df_text = process_tweets(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-05 22:38:56+00:00</td>\n",
       "      <td>Why is not everyone using Satsback to get free...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-05 22:36:12+00:00</td>\n",
       "      <td>@Tether_to @maxkeiser “Bishop of Bitcoin”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-05 22:31:33+00:00</td>\n",
       "      <td>#Rarify, a company that deals with producing i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-05 22:31:28+00:00</td>\n",
       "      <td>@joshmeyerrx No matter how you hold dollars (o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-05 22:24:00+00:00</td>\n",
       "      <td>Dear Crypto bros. We don’t usually see eye to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  created_at  \\\n",
       "0  2022-03-05 22:38:56+00:00   \n",
       "1  2022-03-05 22:36:12+00:00   \n",
       "2  2022-03-05 22:31:33+00:00   \n",
       "3  2022-03-05 22:31:28+00:00   \n",
       "4  2022-03-05 22:24:00+00:00   \n",
       "\n",
       "                                                text  \n",
       "0  Why is not everyone using Satsback to get free...  \n",
       "1          @Tether_to @maxkeiser “Bishop of Bitcoin”  \n",
       "2  #Rarify, a company that deals with producing i...  \n",
       "3  @joshmeyerrx No matter how you hold dollars (o...  \n",
       "4  Dear Crypto bros. We don’t usually see eye to ...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text['label'] = df_text['text'].map(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-05 22:38:56+00:00</td>\n",
       "      <td>Why is not everyone using Satsback to get free...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-05 22:36:12+00:00</td>\n",
       "      <td>@Tether_to @maxkeiser “Bishop of Bitcoin”</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-05 22:31:33+00:00</td>\n",
       "      <td>#Rarify, a company that deals with producing i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-05 22:31:28+00:00</td>\n",
       "      <td>@joshmeyerrx No matter how you hold dollars (o...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-05 22:24:00+00:00</td>\n",
       "      <td>Dear Crypto bros. We don’t usually see eye to ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  created_at  \\\n",
       "0  2022-03-05 22:38:56+00:00   \n",
       "1  2022-03-05 22:36:12+00:00   \n",
       "2  2022-03-05 22:31:33+00:00   \n",
       "3  2022-03-05 22:31:28+00:00   \n",
       "4  2022-03-05 22:24:00+00:00   \n",
       "\n",
       "                                                text     label  \n",
       "0  Why is not everyone using Satsback to get free...  positive  \n",
       "1          @Tether_to @maxkeiser “Bishop of Bitcoin”   neutral  \n",
       "2  #Rarify, a company that deals with producing i...  positive  \n",
       "3  @joshmeyerrx No matter how you hold dollars (o...   neutral  \n",
       "4  Dear Crypto bros. We don’t usually see eye to ...  positive  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
